{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_QA_System_results.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdNqAh6NEIB6"
      },
      "source": [
        "# COVID Q&A System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESqoeGKXENSK"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Load libraries and document corpus to use as context for the Q&A System."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F133OIa97OFQ",
        "outputId": "3fbab48f-44e0-4509-f89f-4e36a7038e34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWoHMktEM0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cacd48a-1d50-4ff4-8ebc-e6e2e3a9eed1"
      },
      "source": [
        "# TO RUN ON GOOGLE COLAB\n",
        "\n",
        "# Install transformers\n",
        "#!pip install transformers\n",
        "# For french\n",
        "!pip install --no-cache-dir transformers sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evA6CCsZjjWn",
        "outputId": "330bf33b-3bc7-4d29-a73b-5d312ee90a29"
      },
      "source": [
        "# Change dir\n",
        "%cd drive/MyDrive/NLP/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "609oXVgDEAYS",
        "outputId": "906ac346-3830-4e5c-b383-08c41ea75515"
      },
      "source": [
        "# Import required libraries for excecution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# NLP\n",
        "from gensim import corpora, models, similarities\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Import utils class\n",
        "sys.path.insert(0,'../')\n",
        "from utils import Utils\n",
        "\n",
        "# Transformer Models\n",
        "from transformers import pipeline\n",
        "\n",
        "# Display\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbVZL3RH7CQ3",
        "outputId": "fb0d144c-3a7d-407d-90ee-be4cb3e3cd8f"
      },
      "source": [
        "# Path to directory of docs\n",
        "#path_prefix = r'D:\\Cesard\\Documents\\NLP'\n",
        "path_prefix = './'\n",
        "lang = 'en'\n",
        "\n",
        "# Instanciate utils class\n",
        "utils = Utils(path_prefix, num_workers=10)\n",
        "\n",
        "# Load WHO and CDC Docs\n",
        "WHO_CDC_text, _, WHO_CDC_titles = utils.data_loader(lang, 'WHO_CDC', total_data=None, max_size = None, return_titles = True )\n",
        "\n",
        "# Load News\n",
        "#news_text, _, news_titles = utils.data_loader(lang, 'news', total_data=1000, max_size=None, return_titles = True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting 10 threads to load 379 documents from WHO_CDC in en\n",
            "Loaded 379 files in 0.21 seconds.\n",
            "Removed 0 files becasuse they were too large\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HgbVdvpV7CQ3"
      },
      "source": [
        "# Append lists\n",
        "doc_text = WHO_CDC_text #+ news_text\n",
        "doc_titles = WHO_CDC_titles #+ news_titles"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mcn-YMjrTDi"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Standard preprocesseing to all documents and queries for the IR task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xs212v4rSGQ"
      },
      "source": [
        "# Stop Words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Stemmers\n",
        "stem = SnowballStemmer('english')\n",
        "#p_stem = PorterStemmer()\n",
        "\n",
        "# Tokenizers\n",
        "#tk = nltk.tokenize.TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "tk = nltk.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Lemmatizer\n",
        "lemma = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Create vocab (dictionary)\n",
        "doc_dict = []\n",
        "for doc in doc_text:\n",
        "    doc_dict.append(utils.preprocessing(text=doc, stop_words = stop_words,\n",
        "                                                  stemmer = None,\n",
        "                                                  tokenizer = tk,\n",
        "                                                  lemmatizer = lemma))\n",
        "# Get dict\n",
        "dictionary = corpora.Dictionary(doc_dict)\n",
        "\n",
        "# Create doc corpus\n",
        "doc_corpus = []\n",
        "for doc in doc_text:\n",
        "    doc_corpus.append(dictionary.doc2bow(utils.preprocessing(text=doc, stop_words = stop_words,\n",
        "                                                                       stemmer = None,\n",
        "                                                                       tokenizer = tk,\n",
        "                                                                       lemmatizer = lemma)))\n",
        "    \n",
        "# Create title corpus\n",
        "title_corpus = []\n",
        "for title in doc_titles:\n",
        "    title_corpus.append(dictionary.doc2bow(utils.preprocessing(text=title, stop_words = stop_words,\n",
        "                                                                           stemmer = None,\n",
        "                                                                           tokenizer = tk,\n",
        "                                                                           lemmatizer = lemma)))\n",
        "\n",
        "# Serializes and saves dictionary and corpus files\n",
        "#dictionary.save('vocab.dict')\n",
        "#corpora.MmCorpus.serialize(\"covid_qa_corpus.mm\", doc_corpus)\n",
        "#corpora.MmCorpus.serialize(\"covid_qa_title.mm\", title_corpus)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKWH-As2shGF"
      },
      "source": [
        "# Load vocabulary, doc_corpus, query_corpus and df with tags\n",
        "#vocabulary = corpora.Dictionary.load('vocab.dict')\n",
        "#doc_corpus = corpora.MmCorpus(\"covid_qa_corpus.mm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHXHwu_3y6z9"
      },
      "source": [
        "## Information Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUobIgF_2Y81"
      },
      "source": [
        "### Create Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI-jePThcUka",
        "outputId": "e87294a1-3da3-4588-8330-09d236d76afa"
      },
      "source": [
        "# Create tfidf model for document corpus\n",
        "tfidf = models.TfidfModel(doc_corpus)\n",
        "tfidf_title = models.TfidfModel(title_corpus)\n",
        "\n",
        "# Model transformation\n",
        "print('Title Doc Example in tfidf form: ')\n",
        "print(tfidf_title[doc_corpus][0]) \n",
        "\n",
        "# Similarity Matrix\n",
        "index = similarities.MatrixSimilarity(tfidf[doc_corpus])\n",
        "index_title = similarities.MatrixSimilarity(tfidf_title[title_corpus])\n",
        "\n",
        "# Save index\n",
        "#index.save('similarity_matrix.index')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title Doc Example in tfidf form: \n",
            "[(0, 0.29810380217412474), (1, 0.29590189482102736), (2, 0.10169570294846703), (3, 0.08291207436260775), (4, 0.14052562327935353), (5, 0.20264852039039022), (6, 0.059965122242362154), (7, 0.10701157626572981), (8, 0.6909548774420143), (9, 0.18561947990613278), (10, 0.23531621953192705), (11, 0.4040441059911029)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhCHywEE2cAO"
      },
      "source": [
        "### Querying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Mn0w3M2Me_"
      },
      "source": [
        "def perform_query(query, top_n = -1):\n",
        "    \"\"\" Perform IR over the corpus with the provided query using gensim tfidf model.\n",
        "    Args:\n",
        "        query (str): raw query (from user input)\n",
        "        top_n (int): max number of docs to retrieve\n",
        "    Returns:\n",
        "        context_doc_ids (list): List with the ids of the context docs\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess query\n",
        "    processed_query = utils.preprocessing(query, \n",
        "                                          stop_words = stop_words,\n",
        "                                          stemmer = None,\n",
        "                                          tokenizer = tk,\n",
        "                                          lemmatizer = lemma)\n",
        "\n",
        "    # Similarity between all docs and query\n",
        "    #sims = list(enumerate(index[tfidf[dictionary.doc2bow(processed_query)]]))\n",
        "\n",
        "    # Similarity between all doc titles and query\n",
        "    sims = list(enumerate(index_title[tfidf_title[dictionary.doc2bow(processed_query)]]))\n",
        "    \n",
        "    dtype = [('doc_id', int), ('score', float)]\n",
        "    doc_sims = np.array(sims, dtype=dtype)\n",
        "    \n",
        "    # Sort Docs by similarity\n",
        "    doc_sims_sorted = np.flip(np.sort(doc_sims, order='score'))\n",
        "\n",
        "    # Retrieve only documents with non zero score\n",
        "    k = len(np.nonzero(doc_sims['score'])[0])\n",
        "    relevant_docs = doc_sims_sorted[0:k]\n",
        "    \n",
        "    # Print only top docs\n",
        "    context_doc_ids = relevant_docs['doc_id'][0:top_n]\n",
        "    \n",
        "    return context_doc_ids"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFcvo0mJF7wd"
      },
      "source": [
        "## Deep Model\n",
        "\n",
        "Load deep pre-trained model for Q&A to extract the answer from the context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSvbU4gCGLBj"
      },
      "source": [
        "# Load pre-trained Q&A Model for lang\n",
        "if lang == 'en':\n",
        "    covid_qa = pipeline(\"question-answering\", model='deepset/roberta-base-squad2-covid')\n",
        "elif lang == 'es':\n",
        "    covid_qa = pipeline(\"question-answering\", model='mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es')\n",
        "elif lang == 'fr':\n",
        "    covid_qa = pipeline('question-answering', model='fmikaelian/camembert-base-fquad', tokenizer='fmikaelian/camembert-base-fquad', use_fast = False)\n",
        "else:\n",
        "    print('Not supported language')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faIZjbVFF7_N"
      },
      "source": [
        "def perform_qa(query, context_ids, confidence_th = 0.05):\n",
        "    \"\"\" Run QA Deep model with query and context from param.\n",
        "    Args:\n",
        "        query (str): raw query (from user input)\n",
        "        context_id (int): document id with the context.\n",
        "    Returns:\n",
        "        result (dir): Answer provided by the model with confidence score.\n",
        "        k (int): Number of context documents found\n",
        "    \"\"\"\n",
        "\n",
        "    # Get context from retrieved docs\n",
        "    for k, id in enumerate(context_ids):\n",
        "        # Get context doc\n",
        "        context = doc_titles[id] + ' ' + doc_text[id]\n",
        "\n",
        "        # Perform QA\n",
        "        result = covid_qa(question=query, context=context)\n",
        "\n",
        "        # If score is good enough return result\n",
        "        if result['score'] > confidence_th:\n",
        "            return result, k\n",
        "    \n",
        "    # Default response if not good enough answer nor context was found\n",
        "    if lang == 'en':\n",
        "        if not len(context_ids):\n",
        "            result = {'answer': 'The context of that question is outside of my domain', 'score': 0}\n",
        "        else:\n",
        "            result = {'answer': 'Sorry, the answer to that question was not found', 'score': 0}\n",
        "    elif lang == 'es':\n",
        "        if not len(context_ids):\n",
        "            result = {'answer': 'El contexto de esa pregunta esta fuera de mi dominio', 'score': 0}\n",
        "        else:\n",
        "            result = {'answer': 'Disculpe, la respuesta a esa pregunta no se encontró', 'score': 0}\n",
        "    elif lang == 'fr':\n",
        "        if not len(context_ids):\n",
        "            result = {'answer': 'Le contexte de cette question est en dehors de mon domaine', 'score': 0}\n",
        "        else:\n",
        "            result = {'answer': 'Pardon, la réponse à cette question n\\'a pas été trouvée', 'score': 0}\n",
        "    else:\n",
        "        print('Not supported language')\n",
        "\n",
        "    return result, 0\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQyxcOk3vL0"
      },
      "source": [
        "## Q&A Demo\n",
        "\n",
        "Demo of the two stage system (IR and Q&A) with some example questions or input from user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmAL9QyX32bm",
        "outputId": "9cd29f4c-8d3d-4ca7-a8b6-926c3318c0dd"
      },
      "source": [
        "# Use input from user\n",
        "print('-------- COVID Q&A -------')\n",
        "q = input('Q: ')\n",
        "print('')\n",
        "\n",
        "# Information Retrieval (get context)\n",
        "context_ids = perform_query(q)\n",
        "\n",
        "# Question Answering\n",
        "result, k = perform_qa(q, context_ids, confidence_th = 0.1)\n",
        "\n",
        "# Print results\n",
        "print(f\"Context Docs (Ranked): \")\n",
        "for i, id in enumerate(context_ids):\n",
        "    print(f\"R{i}: {doc_titles[id]}\")\n",
        "    if i >= k:\n",
        "        print(doc_text[id])\n",
        "        break\n",
        "print('')\n",
        "\n",
        "print(f\"A: {result['answer']}\")\n",
        "print(f\"Score: {result['score']}\")\n",
        "print(f\"Context Doc used: R{k}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------- COVID Q&A -------\n",
            "Q: What is Covid-19?\n",
            "\n",
            "Context Docs (Ranked): \n",
            "R0: What is COVID-19?\n",
            "COVID-19 is a disease caused by a virus called SARS-CoV-2. Most people with COVID-19 have mild  symptoms , but some people can become severely ill. Although most people with COVID-19 get better within weeks of illness, some people experience post-COVID conditions.  Post-COVID conditions  are a wide range of new, returning, or ongoing health problems people can experience  more than four weeks  after first being infected with the virus that causes COVID-19. Older people and those who have  certain underlying medical conditions  are more likely to get severely ill from COVID-19.  Vaccines  against COVID-19 are safe and effective.\n",
            "\n",
            "A: a disease caused by a virus called SARS-CoV-2\n",
            "Score: 0.6684508323669434\n",
            "Context Doc used: R0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBmylVY87CQ8"
      },
      "source": [
        "## Q&A Simple Test\n",
        "\n",
        "Evaluate performance on small hand-made set of questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAF_jN0TEvbG"
      },
      "source": [
        "# Set pandas columns option\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "pd.set_option(\"max_rows\", 30)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZU4vDCu7CQ9"
      },
      "source": [
        "# Functions to compute evaluation metrics\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    em = int(utils.preprocessing(text=prediction, stop_words = stop_words, stemmer = None, tokenizer = tk, lemmatizer = lemma) == utils.preprocessing(text=truth, stop_words = stop_words, stemmer = None, tokenizer = tk, lemmatizer = lemma))\n",
        "    return em\n",
        "\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = utils.preprocessing(text=prediction, \n",
        "                                      stop_words = stop_words,\n",
        "                                      stemmer = None,\n",
        "                                      tokenizer = tk,\n",
        "                                      lemmatizer = lemma)\n",
        "    truth_tokens = utils.preprocessing(text=truth, \n",
        "                                       stop_words = stop_words,\n",
        "                                       stemmer = None,\n",
        "                                       tokenizer = tk,\n",
        "                                       lemmatizer = lemma)\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if pred_tokens == truth_tokens:\n",
        "        return 1\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VMacQd0m7CQ9",
        "outputId": "fb6352c5-4ca9-4914-e322-c915d084d230"
      },
      "source": [
        "# Load hand-made dataset\n",
        "df_test = pd.read_csv(f'qa_{lang}.csv', sep=';', encoding='latin-1')\n",
        "df_test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>real_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is COVID-19?</td>\n",
              "      <td>is the disease caused by a new coronavirus called SARS-CoV-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does COVID-19 spreads?</td>\n",
              "      <td>through close contact from person to person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are covid-19 symptoms?</td>\n",
              "      <td>Fever Dry cough Fatigue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What should I do if I have COVID-19 symptoms?</td>\n",
              "      <td>call your health care provider or COVID-19 hotline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What kind of mask should be used by the general public?</td>\n",
              "      <td>Non-medical, fabric masks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  question                                                   real_answer\n",
              "0                                        What is COVID-19?  is the disease caused by a new coronavirus called SARS-CoV-2\n",
              "1                               How does COVID-19 spreads?                   through close contact from person to person\n",
              "2                              What are covid-19 symptoms?                                       Fever Dry cough Fatigue\n",
              "3            What should I do if I have COVID-19 symptoms?            call your health care provider or COVID-19 hotline\n",
              "4  What kind of mask should be used by the general public?                                     Non-medical, fabric masks"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekU3ihxV-JhF"
      },
      "source": [
        "# Metrics\n",
        "exact_match = []\n",
        "f1_score = []\n",
        "predicted_answer = []\n",
        "docs_retrieved = []\n",
        "\n",
        "for i, q in enumerate(df_test['question']):\n",
        "    print(f\"Answering Q{i}: {q}\")\n",
        "    # Information Retrieval (get context)\n",
        "    context_ids = perform_query(q)\n",
        "\n",
        "    # Question Answering\n",
        "    result, k = perform_qa(q, context_ids, confidence_th = 0.1)\n",
        "\n",
        "    # Compute metrics\n",
        "    docs_retrieved.append(k)\n",
        "    exact_match.append(compute_exact_match(result['answer'], df_test['real_answer'][i]))\n",
        "    f1_score.append(compute_f1(result['answer'], df_test['real_answer'][i]))\n",
        "    predicted_answer.append(result['answer'])\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "T3sQVvHtGJiu",
        "outputId": "6ad10600-e1f1-4d73-ab0a-2aca57070010"
      },
      "source": [
        "# Add results to dataframe\n",
        "df_test['predicted_answer'] = predicted_answer\n",
        "df_test['exact_match'] = exact_match\n",
        "df_test['f1_score'] = f1_score\n",
        "df_test['docs_retrieved'] = docs_retrieved\n",
        "df_test.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>real_answer</th>\n",
              "      <th>predicted_answer</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>docs_retrieved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is COVID-19?</td>\n",
              "      <td>is the disease caused by a new coronavirus called SARS-CoV-2</td>\n",
              "      <td>a disease caused by a virus called SARS-CoV-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does COVID-19 spreads?</td>\n",
              "      <td>through close contact from person to person</td>\n",
              "      <td>when a person with COVID-19 coughs or exhales</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are covid-19 symptoms?</td>\n",
              "      <td>Fever Dry cough Fatigue</td>\n",
              "      <td>Fever Dry cough Fatigue</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What should I do if I have COVID-19 symptoms?</td>\n",
              "      <td>call your health care provider or COVID-19 hotline</td>\n",
              "      <td>seek medical advice</td>\n",
              "      <td>0</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What kind of mask should be used by the general public?</td>\n",
              "      <td>Non-medical, fabric masks</td>\n",
              "      <td>medical mask</td>\n",
              "      <td>0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Can adolescents catch COVID-19?</td>\n",
              "      <td>Yes. All age groups can catch COVID-19.</td>\n",
              "      <td>Yes. All age groups can catch COVID-19.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What distance should I mantain to prevent covid?</td>\n",
              "      <td>6 feet</td>\n",
              "      <td>3 or more days per week</td>\n",
              "      <td>0</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Can my dog spread COVID-19?</td>\n",
              "      <td>the risk of animals spreading COVID-19 to people is considered to be low</td>\n",
              "      <td>a disease caused by a virus called SARS-CoV-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Is there a COVID-19 vaccine?</td>\n",
              "      <td>Yes there are now several vaccines that are in use.</td>\n",
              "      <td>Yes there are now several vaccines that are in use.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Should I get vaccinated if I have had covid?</td>\n",
              "      <td>you should be vaccinated when it is offered to you</td>\n",
              "      <td>Pregnant and recently pregnant people</td>\n",
              "      <td>0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  question  ... docs_retrieved\n",
              "0                                        What is COVID-19?  ...              0\n",
              "1                               How does COVID-19 spreads?  ...              1\n",
              "2                              What are covid-19 symptoms?  ...              0\n",
              "3            What should I do if I have COVID-19 symptoms?  ...              1\n",
              "4  What kind of mask should be used by the general public?  ...             18\n",
              "5                          Can adolescents catch COVID-19?  ...              0\n",
              "6         What distance should I mantain to prevent covid?  ...              0\n",
              "7                              Can my dog spread COVID-19?  ...             18\n",
              "8                             Is there a COVID-19 vaccine?  ...              1\n",
              "9             Should I get vaccinated if I have had covid?  ...             37\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVKZH6pFEiub",
        "outputId": "b7e2f2a2-1852-4667-e658-7b5b210c3a90"
      },
      "source": [
        "print('AVG RESULTS')\n",
        "print(f\"Exact Match: {df_test['exact_match'].mean()}\")\n",
        "print(f\"F1 Score: {df_test['f1_score'].mean()}\")\n",
        "print(f\"Docs Retrieved: {df_test['docs_retrieved'].mean()}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AVG RESULTS\n",
            "Exact Match: 0.3\n",
            "F1 Score: 0.5191827085444107\n",
            "Docs Retrieved: 7.6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98a8de76-8a5d-42c9-af76-5850907bae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Main\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Display\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0ad31e9-f933-44e8-8327-57f2235a5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "utils = Utils('/media/juan/Juan/NLP/', num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b33e6234-83be-49ad-9eb4-1221e2423950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Starting 10 threads to load 500 documents from news in es\n",
      "Loaded 500 files in 15.38 seconds.\n",
      "Removed 0 files becasuse they were too large\n",
      "Starting 10 threads to load 500 documents from FakeNews in es\n",
      "Loaded 500 files in 11.06 seconds.\n",
      "Removed 0 files becasuse they were too large\n",
      "Loaded 500 Tweets 500 Reddit docs\n"
     ]
    }
   ],
   "source": [
    "# Define language\n",
    "lang = 'es'\n",
    "\n",
    "print('Starting...')\n",
    "\n",
    "news_data, _ = utils.data_loader(lang, 'news', total_data=500, max_size = None, return_dates = False)\n",
    "fake_news_data, _ = utils.data_loader(lang, 'FakeNews', total_data=500, max_size = None, return_dates = False)\n",
    "\n",
    "print(f'Loaded {len(news_data)} Tweets {len(fake_news_data)} Reddit docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bca6182-58d1-4770-a090-d8104de70fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuenta de usuarioPremiumServiciosEl León de El Español Publicaciones S.A.\n",
      "                    \n",
      "                                    Portada Sport (21/03/21)\n",
      "                            \n",
      "        \n",
      "        \n",
      "        \n",
      "            \"Al asalto de La Liga\", así titula el diario Sport su portada de este domingo 21 de marzo. El Barcelona necesita la victoria después del triunfo del Real Madrid frente al Celta de Vigo este sábado. Los culés se enfrentan a la Real Sociedad y lo harán sabiendo el resultado del Atlético.Regístrate gratis y recibe cada mañana las noticias en tu correoEugenia Martínez de Irujo explica cómo se encuentra su hermano CayetanoLlegada masiva de inmigrantes a las playas de CeutaMbappe: \"No me da vértigo ser el jugador más...Pallete, Galán y Garralda, entre los asistentes a la presentación del documento 'España 2050'El increíble aspecto del párking y de los nuevos accesos en las obras del Estadio Santiago BernabéuSergio Ramos aprieta y quiere convencer a Zidane para estar contra el VillarrealLa portada del diario Sport (20/05/2021)La portada del diario Mundo Deportivo (20/05/2021)La portada del diario AS (20/05/2021)La portada del diario MARCA (20/05/2021)\n",
      "                        La portada del diario AS (21/03/2021)\n",
      "                    \n",
      "                        La portada del diario Mundo Deportivo (21/03/2021)\n",
      "                    \n",
      "Duro enfrentamiento entre Cristian Ritondo y Nicolás Kreplak por los testeos en Provincia - Clarín. \n",
      "En noviembre de 2018, Cristian Ritondo y Nicolás Kreplak fueron atacados por los testeos contra una camioneta que salía de su domicilio, en la ciudad de Buenos Aires. De acuerdo a la denuncia, al que los dos ingresaron para luego hacer el servicio de teléfono gratuito en el país, los hombres se quedaron en ese entonces en su casa en el barrio de Belgrano. Según la propia denuncia, estos hechos le llevaron a pasar cuatro meses para terminar con el servicio, ya que durante su permanencia en el país se fueron a estudiar medicina en la Universidad Católica de Buenos Aires. Finalmente, no se le permitió pasar el día. \n",
      "\n",
      "La primera denuncia se realizó ante el Juzgado del Crimen n.º 1 de la provincia de Buenos Aires en mayo de 2019. Según la denuncia, entre los hechos violentos estaba el haber sido acusado de agredir al profesor Mario Kreplak, en un ambiente de ambiente conflictivo contra el cual se involucraba el director de escuelas y estudiantes de varias universidades y se encontraba internado. En las páginas del diario El Nación, se informa que según expertos de seguridad de la Provincia de Buenos Aires no hubo agresiones ni incidentes por los mismos. Además, el periodista Daniel J. López afirma que la policía no hubo que preocuparse por las víctimas de los dos ataques.\n",
      "\n",
      "El 16 de junio de 2019, Cristian Ritondo, Cristian Kreplak, Nicolás Kreplak, y Pablo J. Kre\n",
      "-----------------------\n",
      "© 2021 Copyright France 24 - Todos los derechos reservados. El contenido de las páginas externas no es responsabilidad de France 24. Visitas certificadas por el ACPM/OJD.Primera modificación: 04/02/2021 - 14:42Última modificación: 04/02/2021 - 14:40Copenhague (AFP)El impacto de la pandemia de covid-19 en el tratamiento del cáncer es \"catastrófico\", lamentó el jueves la Organización Mundial de la Salud (OMS) en Europa, que señaló interrupciones en los servicios de cancerología en un tercio de los países de la zona.\"El impacto de la pandemia en el cáncer en la región es catastrófico\", dijo el director de la OMS para Europa, Hans Kluge, en el Día Mundial contra el Cáncer.Entre los 53 países de la región para la OMS (varios de Asia Central), uno de cada tres interrumpió parcial o completamente sus servicios de cancerología debido a la movilización contra la pandemia y las restricciones de viaje.\"Algunos países tuvieron escasez de medicamentos contra el cáncer y muchos han visto una caída significativa de nuevos diagnósticos de cáncer, incluso en los países más ricos \", dijo Kluge en un comunicado, señalando que las desigualdades han empeorado debido a la crisis económica.En Holanda y Bélgica, durante el primer confinamiento en la primavera boreal de 2020, el número de cánceres diagnosticados se redujo entre un 30% y un 40%, señaló el funcionario de la ONU.En Kirguistán, cayó un 90% en abril de 2020, agregó.En el Reino Unido, los retrasos en el diagnóstico y el tratamiento provocarán un aumento del 15% de la mortalidad por cáncer colorrectal y del 9% por cáncer de mama en los próximos cinco años, prevé la OMS.En la región europea, los cánceres, la diabetes y las enfermedades respiratorias crónicas son responsables de más del 80% de las muertes cada año.La OMS tiene la intención de volver a movilizar a las autoridades con una iniciativa centrada en particular en la prevención, la detección temprana y el acceso de todos al diagnóstico y tratamiento.© 2021 AFPEl contenido que solicitó no existe o ya no está disponible.\n",
      "La aviación comercial sostenible es posible a medio plazo - Actualidad Aeroespacial. \n",
      "Inicio de una inversión económica óptima para el desarrollo de esta industria en los próximos años se puede observar en: \n",
      "\n",
      "\n",
      "Las tecnologías más utilizadas y las áreas de aplicación adecuadas a estas son: \n",
      "El desarrollo económico y su aplicación puede desarrollarse hacia los siguientes objetivos:\n",
      "\n",
      "\n",
      "\n",
      "La infraestructura necesaria para cubrir el tráfico aéreo comercial de la actualidad, que se encuentra en proceso de evolución y evolución, puede incluir: aeropuertos, autopistas, aeropuertos de peaje, ferrocarriles, autopistas, aeropuertos, aeropuertos y aeropuertos de peaje - aeropuertos en la zona y en zonas geográficas costeras.\n",
      "\n",
      "Los aeropuertos que forman parte de la \"marketing-empresa\" son:\n",
      "\n",
      "\n",
      "Otras áreas que generan ingresos para el municipio son: \n",
      "\n",
      "\n",
      "En la actualidad, el concepto de inversión se basa en la información relacionada con las tecnologías, así como en los valores relacionados con la empresa. Este concepto puede ser interpretado como: \n",
      "\n",
      "\n",
      "Los conceptos de inversión como la aplicación de la red del transporte son, por tanto, muy similares a los de los aeropuertos. Los aeropuertos con los que el transporte y la economía se sustentan, ya sea para el área del tráfico o también a distancias a otras ciudades o sitios donde este recurso pueda extenderse y aprovechar a la empresa. Por lo general, la inversión se centra en la construcción de infraestructura adecuada para llevar a cabo servicios como el traslado de la carga de carga y pasajeros, conexión a destinos de carga más cercano y transporte aéreo a zonas donde este transporte no puede ser un recurso. Ejemplos de instalaciones de inversión en el uso de la infraestructura de comunicación\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(news_data[i])\n",
    "    print(fake_news_data[i])\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "016a639f-cf70-43f7-a052-7d1c6899a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = news_data + fake_news_data\n",
    "tags = [1]*len(news_data) + [0]*len(fake_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3750d925-0429-4f91-a818-9717db193434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Stemmers\n",
    "stem = SnowballStemmer('english')\n",
    "#p_stem = PorterStemmer()\n",
    "\n",
    "# Tokenizers\n",
    "#tk = nltk.tokenize.TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "tk = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Lemmatizer\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Preprocess data\n",
    "corpus = []\n",
    "for d in data:\n",
    "    corpus.append(utils.preprocessing(d, stop_words = stop_words,\n",
    "                                         stemmer = None,\n",
    "                                         tokenizer = tk,\n",
    "                                         lemmatizer = lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e605f246-1e02-4a1b-8a1e-e997290ff07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[0] = corpus[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7031c2fd-fe81-49a8-8bab-573518845f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3be3a506-a3b9-4733-b928-3391069e99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/bert-base-uncased-ag-news were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-ag-news\")\n",
    "model = AutoModel.from_pretrained(\"textattack/bert-base-uncased-ag-news\", output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "801151b0-f929-40f1-a529-c38cd77f273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model for first sentence\n",
    "inputs = tokenizer(corpus[0][:259], return_tensors=\"pt\", is_split_into_words=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Just pooler output as embeddings\n",
    "embedding = outputs['pooler_output'].detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546bb653-c5c5-4ebb-adbe-c5176659dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<06:20,  2.62it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "  8%|▊         | 81/1000 [00:08<03:13,  4.74it/s]"
     ]
    }
   ],
   "source": [
    "# Array to save embeddings\n",
    "reu_embeddings = []\n",
    "\n",
    "failed_doc_ids = []\n",
    "\n",
    "for i, doc in enumerate(tqdm(corpus)):\n",
    "    try:\n",
    "        # Run Bert for each document\n",
    "        inputs = tokenizer(doc, return_tensors=\"pt\", is_split_into_words=True)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # CLS Token Output\n",
    "        embedding = outputs['pooler_output'].detach().numpy()[0]\n",
    "        \n",
    "        # Append representation\n",
    "        reu_embeddings.append(embedding)\n",
    "        \n",
    "    except:\n",
    "        failed_doc_ids.append(i)\n",
    "    \n",
    "print(f'Failed to tokenize {len(failed_doc_ids)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e91c-bdd9-4f77-9daa-c5ca069392fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove failed docs\n",
    "for i, doc_id in enumerate(failed_doc_ids):\n",
    "    corpus.pop(doc_id - 1)\n",
    "    tags.pop(doc_id - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8f8e9-56a3-4fa4-ad66-81cd5817e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reu_embeddings\n",
    "y = tags\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "clf = MLPClassifier(random_state=1, max_iter=700).fit(X_train, y_train)\n",
    "clf.score(X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

Tratando explícitamente el tema de detección de temas en \textit{Twitter} los autores de  \cite{ReviewApproachesTopcicDetection} realizan un recuento de diferentes métodos que buscan solucionar el problema. Inicia por explicar y comparar acercamientos tradicionales que varían en la manera en que se representan los temas que son tendencia: la estrategia pivot de documentos los representa como un agrupamiento de documentos mientras que pivot de características los representa como un agrupamiento de palabras claves.\\

Posteriormente presenta una tabla que resume la manera en que diferentes algoritmos propuestos dan solución resaltando características del mismo: \textit{embedding} o no \textit{embedding}, eventos específicos o no específicos, y detección supervisada y no supervisada. Profundizando en la primera comparación, la diferencia radica en qué tipo de modelos se utilizan para la representación de las palabras. Los métodos que no utilizan \textit{embeddings} implementan modelos como \textit{Bag of Words} o \textit{TF-IDF}, los cuales según \cite{ReviewApproachesTopcicDetection} sufren de poca capacidad de generalización, dado, entre otros, a que se basa en la re-ocurrencia de palabras, lo cual en documentos cortos resulta poco probable. Por su parte la utilización de \textit{embeddings} consiste en la representación continua de palabras en un idioma mapeándolas como vectores de un espacio dimensional bajo. Esta técnica es más reciente y ofrece mejores resultados en varias tareas de procesamiento de lenguaje natural. Siguiendo con las diferencias, los eventos indican la información que se conoce de cada observación del conjunto de datos, como por ejemplo localización, hora, fecha, etc. La tercera categoría depende de si la detección es supervisada o no supervisada, dependiendo de si se poseen las etiquetas correctas de cada observación o no. Esto incide ampliamente en el tipo de modelo de \textit{Machine Learning} a utilizar.\\

En \cite{TrendTopicsDetectionFromTwitter} y \cite{FuzzyIncrementalTopicDetection} se presentan diferentes aproximaciones de agrupamiento de temas y tendencias haciendo extracción de palabras claves de cada documento. Inician por el preprocesamiento en donde se remueven caracteres especiales y puntuación, lematización. Posteriormente se descubren vectores de temas aplicando HDA (Hierarchical Dirichlet Processes) y se utiliza para encontrar la distribución de tópicos en cada tweets, donde el que tiene mayor probabilidad corresponde al tema tendencia. Finalmente, para cada uno de los grupos de temas se crea un grafo de dependencia entre \textit{tweets} midiendo la similaridad de los mismos.\\

En \cite{DeepRepresentationClusteringTweets} y \cite{UnsupervisedDeepEmbeddingClustering} muestran las ventajas y beneficio en los resultados que se puede obtener a través de la utilización de modelos profundos, como autoencoders y redes neuronales del estado del arte como Bert, para obtener un \textit{embedding} más adecuado y que finalmente beneficia el método de agrupamiento utilizado. Estas últimas referencias muestran algo de la tendencia actual en la gran mayoría de retos del procesamiento de lenguaje natural, pues antes de proponer nuevos algoritmos de clasificación o \textit{clustering} se ha procurado desarrollar y mejorar las herramientas que se utilizan para representar matemáticamente los documentos.